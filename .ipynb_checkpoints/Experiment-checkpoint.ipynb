{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import gym\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from Deployment.buffer.video import VideoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data from json files. Return list of json loads from different files.\n",
    "\"\"\"\n",
    "def load():\n",
    "    all_data = []\n",
    "    \n",
    "    for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        next_file = 'data/%i_0.json'%i\n",
    "        data = []\n",
    "        while True:\n",
    "            with open(next_file, 'r') as f:\n",
    "                d = json.load(f)\n",
    "                data.extend(d['data'])\n",
    "                if 'cont_file' in d.keys() and os.path.isfile(d['cont_file']):\n",
    "                    next_file = d['cont_file'] \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        all_data.append({'video': d['video'], 'data':data})\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a dictionary of tracks where keys are tuples of videopath and track id \n",
    "and values the detection encodings associated with them.\n",
    "    \n",
    "Input argument, data, is a list of json loaded files.\n",
    "\"\"\"\n",
    "def tracks(data):\n",
    "    # List of\n",
    "    key_set = set()\n",
    "    track_dict = dict()\n",
    "    for cur_data in data:\n",
    "        \n",
    "        filename = cur_data['video']\n",
    "        for d in cur_data['data']:\n",
    "            if 'track_id' not in d.keys() or d['track_state'] != 2:\n",
    "                continue\n",
    "\n",
    "            key = (filename, d['track_id']) \n",
    "\n",
    "            # d.pop('track_id') # no need anymore\n",
    "            # d.pop('track_state')# no need anymore\n",
    "\n",
    "            if key not in key_set:\n",
    "                track_dict[key] = []\n",
    "                key_set.add(key)\n",
    "                \n",
    "            track_dict[key].append(d)\n",
    "\n",
    "    return track_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Statistics required to define the reward function. \n",
    "The statistics variable below is self explanotary about the content returned.\n",
    "\"\"\"\n",
    "def stats(track_data):\n",
    "    confs = {'age':[], 'gender':[]}\n",
    "    changes_in_entropy = {'age': [], 'gender': []}\n",
    "    for key, track in track_data.items():\n",
    "        prev_state = None\n",
    "        for d in track:\n",
    "            state = State(d, prev_state=prev_state)\n",
    "            if prev_state is not None:\n",
    "                for K in ['age', 'gender']:\n",
    "                    changes_in_entropy[K].append(prev_state.entropy[K] - state.entropy[K])\n",
    "            prev_state = state\n",
    "            confs['age'].append(np.max(d['age_conf']))\n",
    "            confs['gender'].append(np.max(d['gender_conf']))\n",
    "    \n",
    "    statistics = (np.mean(confs['gender']), \n",
    "                  np.mean(confs['age']), \n",
    "                  np.mean(changes_in_entropy['gender']),\n",
    "                  np.mean(changes_in_entropy['age']),\n",
    "                  np.std(confs['gender']), \n",
    "                  np.std(confs['age']),\n",
    "                  np.std(changes_in_entropy['gender']), \n",
    "                  np.std(changes_in_entropy['age']))\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get reward function as lambda\n",
    "\"\"\"\n",
    "\n",
    "def reward_func_linear(stats, verbose = False):\n",
    "    mean_conf_gender, mean_conf_age, mean_entropy_change_gender, mean_entropy_change_age, dev_conf_gender, dev_conf_age,dev_entropy_change_gender, dev_entropy_change_age = stats\n",
    "    if verbose:\n",
    "        print(\"Maximum confidences in GENDER classification has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_conf_gender, dev_conf_gender))\n",
    "        print(\"Maximum confidences in AGE classification has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_conf_age, dev_conf_age))\n",
    "        print(\"Entropy change for GENDER has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_entropy_change_gender, dev_entropy_change_gender))\n",
    "        print(\"Entropy change for AGE has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_entropy_change_age, dev_entropy_change_age))\n",
    "        \n",
    "    \n",
    "    # Params: action -> 0 or 1, states -> State objects\n",
    "    def func(prev_state, action, state):\n",
    "        c_g = state.latest_confidence('gender')\n",
    "        c_a = state.latest_confidence('age')\n",
    "        \n",
    "        cost = action\n",
    "        reward_conf = action*.5*(((c_g - mean_conf_gender)/dev_conf_gender) + 1) +\\\n",
    "                      action*.5*(((c_a - mean_conf_age)/dev_conf_age) + 1)\n",
    "        \n",
    "        if prev_state is None:\n",
    "            return reward_conf - cost\n",
    "        else:\n",
    "            alpha = .3\n",
    "            ec_g = prev_state.entropy['gender'] - state.entropy['gender']\n",
    "            ec_a = prev_state.entropy['age'] - state.entropy['age']\n",
    "\n",
    "            reward_entropy = action*.5*(((ec_g - mean_entropy_change_gender)/dev_entropy_change_gender) + 1) +\\\n",
    "                             action*.5*(((ec_a - mean_entropy_change_age)/dev_entropy_change_age) + 1)\n",
    "            \n",
    "            return (alpha * reward_conf + (1 - alpha) * reward_entropy) - cost\n",
    "            \n",
    "    return func\n",
    "\n",
    "\"\"\"\n",
    "Reward function with minor twist. \n",
    "Note: Didn't work very well!\n",
    "\"\"\"\n",
    "\n",
    "def reward_func_decay(stats, verbose = False):\n",
    "    mean_conf_gender, mean_conf_age, mean_entropy_change_gender, mean_entropy_change_age, dev_conf_gender, dev_conf_age,dev_entropy_change_gender, dev_entropy_change_age = stats\n",
    "    if verbose:\n",
    "        print(\"Maximum confidences in GENDER classification has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_conf_gender, dev_conf_gender))\n",
    "        print(\"Maximum confidences in AGE classification has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_conf_age, dev_conf_age))\n",
    "        print(\"Entropy change for GENDER has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_entropy_change_gender, dev_entropy_change_gender))\n",
    "        print(\"Entropy change for AGE has mean %.4f and standard deviation %.4f\" % (\n",
    "        mean_entropy_change_age, dev_entropy_change_age))\n",
    "        \n",
    "    # Params: action -> 0 or 1, states -> State objects\n",
    "    def func(prev_state, action, state):\n",
    "        c_g = state.latest_confidence('gender')\n",
    "        c_a = state.latest_confidence('age')\n",
    "        n = state.n\n",
    "        cost = action\n",
    "        reward_conf = 1/n * action*.5*(((c_g - mean_conf_gender)/dev_conf_gender) + 1) +\\\n",
    "                      1/n * action*.5*(((c_a - mean_conf_age)/dev_conf_age) + 1)\n",
    "        \n",
    "        if prev_state is None:\n",
    "            return reward_conf - cost\n",
    "        else:\n",
    "            alpha = .3\n",
    "            ec_g = prev_state.entropy['gender'] - state.entropy['gender']\n",
    "            ec_a = prev_state.entropy['age'] - state.entropy['age']\n",
    "\n",
    "            reward_entropy = action*.5*(((ec_g - mean_entropy_change_gender)/dev_entropy_change_gender) + 1) +\\\n",
    "                             action*.5*(((ec_a - mean_entropy_change_age)/dev_entropy_change_age) + 1)\n",
    "            \n",
    "            return (alpha * reward_conf + (1 - alpha) * reward_entropy) - cost\n",
    "            \n",
    "    return func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(gym.Space):\n",
    "    def __init__(self, encoding, prev_state = None):\n",
    "        \"\"\"\n",
    "        params:\n",
    "        prev_state : State object representing precious state\n",
    "        encoding : a dictionary conatining information of this state's confidences, box, feature  \n",
    "        \"\"\"\n",
    "        self.confs = {'age':np.expand_dims(encoding['age_conf'], 0), \n",
    "                      'gender':np.expand_dims(encoding['gender_conf'], 0)}\n",
    "        if prev_state is not None:\n",
    "            self.confs['age'] = np.concatenate([self.confs['age'], prev_state.confs['age']], axis = 0)\n",
    "            self.confs['gender'] = np.concatenate([self.confs['gender'], prev_state.confs['gender']], axis = 0)\n",
    "        self.n = len(self.confs['age'])\n",
    "        self.probs = {'age': np.mean(self.confs['age'], axis = 0), 'gender': np.mean(self.confs['gender'], axis = 0)}\n",
    "        self.entropy = {'age': np.sum(self.probs['age'] * np.log2(1/self.probs['age'])), \n",
    "                        'gender': np.sum(self.probs['gender'] * np.log2(1/self.probs['gender']))}\n",
    "\n",
    "        self.feature = encoding['feature']\n",
    "        \n",
    "        t, l, b, r = encoding['box']\n",
    "        self.resolution = max(b - t, r - l)\n",
    "    \n",
    "    def latest_confidence(self, key = 'gender'):\n",
    "        \"\"\"\n",
    "        Helper method used in reward function\n",
    "        Returns latest recorded confidence score for given key (age or gender).\n",
    "        \"\"\"\n",
    "        return max(self.confs[key][0])\n",
    "    \n",
    "    def max_prob(self, key = 'gender'):\n",
    "        return max(self.probs[key])\n",
    "    \n",
    "    def vectorize(self):\n",
    "        \"\"\"\n",
    "        Concatenate information representing this state and return a 1D vector.\n",
    "        \"\"\"\n",
    "        vec1 = self.feature\n",
    "        vec2 = np.array([self.entropy['gender'], \n",
    "                         self.entropy['age'],\n",
    "                         self.max_prob(key = 'gender'),\n",
    "                         self.max_prob(key = 'age'),\n",
    "                         # self.n, # Test again\n",
    "                         self.latest_confidence(key = 'gender'),\n",
    "                         self.latest_confidence(key = 'age')])\n",
    "        vector = np.expand_dims(np.concatenate([vec1, vec2]), axis = 0)\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class that inherits from the gym.Env.\n",
    "\n",
    "States are composed of facial features and resolutions.\n",
    "\n",
    "Actions are discrete: 0 and 1, representing predict or not predict\n",
    "\n",
    "This environment works with the following reward function:\n",
    "    R= a * 0.5·((C​gender​ -​ μ​gender + 1)​·/​σg​ender+​ (C​age​ -​ μ​age + 1​)/​σ​gender​) - 1\n",
    "\n",
    "\"\"\"\n",
    "age_groups = [[0, 8], [8, 15], [15, 20], [20, 25], [25, 32], [32, 35], [35, 38], [38, 43], [43, 48], [48, 53], [53, 60], [60, 200]]\n",
    "genders = ['Female', 'Male']\n",
    "\n",
    "class myEnv(gym.Env):\n",
    "    metadata = {'render.modes' : ['human']}\n",
    "    \n",
    "    def __init__(self, mode = 'human'):\n",
    "        raw_data = load() # Load raw data\n",
    "        self.data = tracks(raw_data) # Format and store\n",
    "        self.stats = stats(self.data) # Statistics such as mean_age_conf, mean_gender_conf, mean_entropy_change and variances\n",
    "        self.datalen = len(self.data) # Useful variable\n",
    "        self.datagen = self.generator() # Will be used by reset function to fetch the next sequence of elems\n",
    "        self.gencycle = 0 # Which cycle is the generator in. 1 cycle means an iterataion through the entire dataset\n",
    "        self.compute_reward = reward_func_linear(self.stats, verbose = False) # Confidence gender and age as inputs to this func\n",
    "        self.cur_state = None \n",
    "        self.cur_reward = None # Useful for displaying\n",
    "        self.cur_key = None # Is set by self.reset. \n",
    "        self.cur_idx = 0 # Is incremented by self.step\n",
    "        self.cur_enc = None # Is set by self.step and used by self.render\n",
    "        self.cur_action = None\n",
    "        self.buffer = None # Buffer of frames in current video\n",
    "        self.cap = None # VideoCapture object\n",
    "        self.done = False # Set to True if current sequence is done. Useful to raise error in self.step\n",
    "        self.cur_fid = None # Sert to current frame_id. Useful in rendering\n",
    "        self.window_name = 'frame' # Used in rendering\n",
    "        self.mode = mode\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "    \n",
    "    def draw(self, frame):\n",
    "        frame = copy.deepcopy(frame)\n",
    "        gender = genders[self.cur_enc['gender']]\n",
    "        age = age_groups[self.cur_enc['age']]\n",
    "        box = self.cur_enc['box']\n",
    "        t, l, b, r = list(map(int, box))\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (255, 100, 100), 2)\n",
    "\n",
    "        if self.mode == 'human':\n",
    "            txt = gender + ' ' + str(age) + \\\n",
    "            \"  Reward: \"+ str(round(self.cur_reward, 3))\n",
    "            cv2.putText(frame, txt, (700, 700), cv2.FONT_HERSHEY_SIMPLEX, .5, (200, 100, 220), 2)\n",
    "        elif self.mode == 'test':\n",
    "            if self.cur_action == 1:\n",
    "                frame[t:b, l:r][:, :, 0] = 20\n",
    "            txt = \"Action: %i\"%self.cur_action\n",
    "            cv2.putText(frame, txt, (900, 700), cv2.FONT_HERSHEY_SIMPLEX, .5, (200, 100, 220), 2)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # frame = cv2.resize(frame, (640, 360))\n",
    "        return frame\n",
    "        \n",
    "    def render(self):\n",
    "        if self.mode in ['human', 'test']:\n",
    "            # print(\"Buffer length:\", len(self.buffer), \"cur_fid:\", self.cur_fid)\n",
    "            tic = time.time()\n",
    "            frame = self.draw(self.buffer[self.cur_fid])\n",
    "\n",
    "            cv2.imshow(self.window_name, frame)\n",
    "\n",
    "            k = cv2.waitKey(30)\n",
    "            if k == 27:\n",
    "                sys.exit(0)\n",
    "\n",
    "            toc = time.time()\n",
    "            # print('FPS:',1/(toc - tic))\n",
    "\n",
    "            \n",
    "    \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"Action should be 0 or 1.\"\n",
    "        if self.done:\n",
    "            raise ValueError(\"Please reset environment before performing another step\")\n",
    "        \n",
    "        # Store cur state \n",
    "        state = self.cur_state\n",
    "        \n",
    "        # Assign current state, current encoding, current reward, and current frame id\n",
    "        next_enc = self.data[self.cur_key][self.cur_idx] # Returns a detection encoding in dict format\n",
    "        next_state = State(next_enc, prev_state=state)\n",
    "        reward = self.compute_reward(state, action, next_state)\n",
    "        \n",
    "        self.cur_enc = next_enc\n",
    "        self.cur_state = next_state\n",
    "        self.cur_reward = reward\n",
    "        self.cur_action = action\n",
    "        self.cur_fid = self.cur_enc['frame_id'] - 1\n",
    "        \n",
    "        # Check if done\n",
    "        done = False\n",
    "        if self.cur_idx == len(self.data[self.cur_key]) - 1:\n",
    "            done = True\n",
    "        \n",
    "        # Increment idx\n",
    "        self.cur_idx += 1\n",
    "        \n",
    "        return state, reward, next_state, done\n",
    "            \n",
    "    def reset(self, close = False):\n",
    "        # Generate next key \n",
    "        self.cur_key = next(self.datagen)\n",
    "        \n",
    "        # Set idx to 0\n",
    "        self.cur_idx = 0\n",
    "        \n",
    "        # Assign current state, current encoding, and current frame id\n",
    "        self.cur_enc = self.data[self.cur_key][self.cur_idx]\n",
    "        self.cur_state = State(self.cur_enc, prev_state=self.cur_state)\n",
    "        self.cur_fid = self.cur_enc['frame_id'] - 1\n",
    "        self.cur_reward = 0\n",
    "        \n",
    "        if self.mode in ['human', 'test']:\n",
    "            filepath, track_id = self.cur_key\n",
    "            if self.cap is not None and self.cap.pipeline == filepath:\n",
    "                print(\"\\tTrack_id:\", track_id)\n",
    "                return\n",
    "            \n",
    "            elif self.cap is not None and filepath != self.cap.pipeline:\n",
    "                self.cap.close()\n",
    "            \n",
    "            \n",
    "            self.cap = VideoCapture(filepath, shape = (720, 1280))\n",
    "\n",
    "            # Read all frames into self.buffer\n",
    "            self.buffer = []\n",
    "            while True:\n",
    "                if len(self.buffer) % 1000 == 0 and len(self.buffer) != 0:\n",
    "                    print(\"Loading %ith frame into buffer\"%len(self.buffer))\n",
    "                try:\n",
    "                    self.buffer.append(self.cap.read()) # Read frame\n",
    "                except BufferError as e:\n",
    "                    break\n",
    "            print(\"Video in buffer:\", self.cap.pipeline, \"\\t# of frames in buffer:\", len(self.buffer), \"\\tTrack_id:\", track_id)\n",
    "        \n",
    "    def generator(self):\n",
    "        while True:\n",
    "            seq = random.sample(list(self.data.keys()), k = self.datalen)\n",
    "            for nextkey in seq:\n",
    "                yield nextkey        \n",
    "            self.gencycle += 1\n",
    "    \n",
    "    def reset_gen(self):\n",
    "        self.datagen = self.generator()\n",
    "        self.gencycle = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q-learning\n",
    "\"\"\"\n",
    "class Algo:\n",
    "    def __init__(self, env, discount = 0.9):\n",
    "        self.env = env\n",
    "        self.discount = discount\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.Dense(2, input_shape = (1030,)))\n",
    "        self.model.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "        \n",
    "        \n",
    "    def doOneEpisode(self):\n",
    "        self.env.reset()\n",
    "        transitionList = []\n",
    "        while True:\n",
    "            # Visualize if env.mode == 'human'\n",
    "            self.env.render()\n",
    "            \n",
    "            # Select action randomly \n",
    "            action = self.env.action_space.sample()\n",
    "            \n",
    "            # Single step\n",
    "            state, reward, next_state, done = self.env.step(action)\n",
    "\n",
    "            \n",
    "            # Append (state, reward) to eps\n",
    "            transitionList.append((state, action, reward, next_state, done))\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        return transitionList\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs):\n",
    "        self.env.mode = 'mac'\n",
    "        self.env.reset_gen()\n",
    "        cur_epoch = 0\n",
    "        while self.env.gencycle < epochs:\n",
    "            X = []\n",
    "            Y = []\n",
    "            transitionList = self.doOneEpisode()\n",
    "            for state, action, reward, next_state, done in transitionList:\n",
    "                # algo.env.render()\n",
    "                if done:\n",
    "                    q_next = 0\n",
    "                else:\n",
    "                    q_next = np.max(self.model.predict(next_state.vectorize()))\n",
    "                q_target = reward + self.discount * q_next\n",
    "                target = self.model.predict(state.vectorize())\n",
    "                target[0][action] = q_target\n",
    "                clear_output(wait=True)\n",
    "                display('%ith epoch -- file %s -- track_id %i'%(cur_epoch, self.env.cur_key[0], self.env.cur_key[1]))\n",
    "                self.model.fit(X, Y, epochs = 1, verbose = 0)    \n",
    "            cur_epoch = self.env.gencycle\n",
    "\n",
    "    def render_test(self):        \n",
    "        self.env.mode = 'test'\n",
    "        self.env.reset()\n",
    "        cur_state = self.env.cur_state\n",
    "        while True:\n",
    "            q = self.model.predict(cur_state.vectorize())\n",
    "            action = np.argmax(q[0])\n",
    "            _, _, next_state, done = self.env.step(action)\n",
    "            cur_state = next_state\n",
    "            self.env.render()\n",
    "            if done:\n",
    "                self.env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algo(myEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video in buffer: ../../Vids/test/people.mp4 \t# of frames in buffer: 351 \tTrack_id: 36\n",
      "Video in buffer: ../../Vids/test/oscars2.mp4 \t# of frames in buffer: 613 \tTrack_id: 84\n",
      "Video in buffer: ../../Vids/test/marathon_4.mp4 \t# of frames in buffer: 305 \tTrack_id: 105\n",
      "Video in buffer: ../../Vids/test/people2.mp4 \t# of frames in buffer: 528 \tTrack_id: 111\n",
      "Video in buffer: ../../Vids/test/oscars2.mp4 \t# of frames in buffer: 613 \tTrack_id: 41\n",
      "Video in buffer: ../../Vids/test/cnn_2_short.mp4 \t# of frames in buffer: 297 \tTrack_id: 5\n",
      "Video in buffer: ../../Vids/test/marathon_2.mp4 \t# of frames in buffer: 281 \tTrack_id: 67\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoelmolinas/anaconda3/envs/eyetracking/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "algo.render_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0th epoch -- file ../../Vids/test/marathon_2.mp4 -- track_id 97'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "algo.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video in buffer: ../../Vids/test/oscars2.mp4 \t# of frames in buffer: 613 \tTrack_id: 93\n",
      "Video in buffer: ../../Vids/test/marathon_6.mp4 \t# of frames in buffer: 164 \tTrack_id: 106\n",
      "Video in buffer: ../../Vids/test/oscars2.mp4 \t# of frames in buffer: 613 \tTrack_id: 90\n",
      "Video in buffer: ../../Vids/test/cnn_2_short.mp4 \t# of frames in buffer: 297 \tTrack_id: 13\n",
      "Video in buffer: ../../Vids/test/oscars2.mp4 \t# of frames in buffer: 613 \tTrack_id: 85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-294815dcf4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0abd20d1e26d>\u001b[0m in \u001b[0;36mrender_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mcur_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1d1f74714fa2>\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo.render_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.model.save(\"fena_degil.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tracks(load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.3\n",
    "size = len(d)\n",
    "test_size = int(size * ratio)\n",
    "train_size = size - test_size\n",
    "len(random.sample(d.items(), k = train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x():\n",
    "    for i in range(10):\n",
    "        yield 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object x at 0x11198eba0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = x()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
